{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KDfgWld2r8Vi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "467275e4-70b4-442d-f0c6-48e2afc56c6b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.7169, 0.0000, 0.3628, 0.9614],\n",
              "         [0.5407, 0.0000, 0.3420, 0.9329],\n",
              "         [0.3734, 0.0000, 0.1991, 0.7542]]),\n",
              " 5.183506011962891)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# 3x4 크기의 랜덤 값을 가진 텐서 생성\n",
        "tensor = torch.rand(3, 4)\n",
        "\n",
        "# 생성된 텐서의 두 번째 열을 모두 0으로 변경\n",
        "tensor[:, 1] = 0\n",
        "\n",
        "# 텐서의 모든 원소를 합한 값 계산\n",
        "tensor_sum = torch.sum(tensor)\n",
        "\n",
        "tensor, tensor_sum.item()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# 5x5 크기의 랜덤 텐서 생성 (0~1 사이의 균일 분포)\n",
        "tensor = torch.rand(5, 5)\n",
        "print(\"생성된 텐서:\\n\", tensor)\n",
        "\n",
        "# 값이 0.5보다 큰 값만 추출하여 1차원 텐서로 변환\n",
        "mask = tensor > 0.5\n",
        "result = tensor[mask].flatten()\n",
        "print(\"0.5보다 큰 값들:\\n\", result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBYPOwTVs93V",
        "outputId": "077039b0-aee7-475a-ec8c-c2e7f31c3919"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "생성된 텐서:\n",
            " tensor([[0.7278, 0.0382, 0.0804, 0.0520, 0.3410],\n",
            "        [0.2084, 0.3740, 0.2292, 0.3091, 0.6425],\n",
            "        [0.2721, 0.5637, 0.2318, 0.7228, 0.1586],\n",
            "        [0.4741, 0.0535, 0.5001, 0.1673, 0.0192],\n",
            "        [0.6591, 0.6504, 0.5484, 0.0436, 0.4015]])\n",
            "0.5보다 큰 값들:\n",
            " tensor([0.7278, 0.6425, 0.5637, 0.7228, 0.5001, 0.6591, 0.6504, 0.5484])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# 4x4 크기의 랜덤 NumPy 배열 생성\n",
        "numpy_array = np.random.rand(4, 4)\n",
        "print(\"NumPy 배열:\\n\", numpy_array)\n",
        "\n",
        "# NumPy 배열을 PyTorch Tensor로 변환\n",
        "tensor = torch.from_numpy(numpy_array)\n",
        "print(\"Tensor:\\n\", tensor)\n",
        "\n",
        "# Tensor를 파일로 저장 (torch.save)\n",
        "torch.save(tensor, 'my_tensor.pt')\n",
        "print(\"Tensor가 파일로 저장되었습니다.\")\n",
        "\n",
        "# 저장된 파일에서 Tensor 불러오기\n",
        "loaded_tensor = torch.load('my_tensor.pt')\n",
        "print(\"불러온 Tensor:\\n\", loaded_tensor)\n",
        "\n",
        "# 원본 Tensor와 불러온 Tensor 비교 (torch.equal)\n",
        "if torch.equal(tensor, loaded_tensor):\n",
        "    print(\"두 Tensor는 동일합니다.\")\n",
        "else:\n",
        "    print(\"두 Tensor가 다릅니다.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEB4l6oVwAag",
        "outputId": "d5465a0d-6cb3-4a69-8ead-f860b07b876a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy 배열:\n",
            " [[0.43149849 0.59325513 0.32168599 0.91427846]\n",
            " [0.12820305 0.15502603 0.60113535 0.11622248]\n",
            " [0.19813143 0.72552258 0.1347216  0.77121571]\n",
            " [0.76437703 0.75575872 0.44910634 0.99194489]]\n",
            "Tensor:\n",
            " tensor([[0.4315, 0.5933, 0.3217, 0.9143],\n",
            "        [0.1282, 0.1550, 0.6011, 0.1162],\n",
            "        [0.1981, 0.7255, 0.1347, 0.7712],\n",
            "        [0.7644, 0.7558, 0.4491, 0.9919]], dtype=torch.float64)\n",
            "Tensor가 파일로 저장되었습니다.\n",
            "불러온 Tensor:\n",
            " tensor([[0.4315, 0.5933, 0.3217, 0.9143],\n",
            "        [0.1282, 0.1550, 0.6011, 0.1162],\n",
            "        [0.1981, 0.7255, 0.1347, 0.7712],\n",
            "        [0.7644, 0.7558, 0.4491, 0.9919]], dtype=torch.float64)\n",
            "두 Tensor는 동일합니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-08a605b38951>:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  loaded_tensor = torch.load('my_tensor.pt')\n"
          ]
        }
      ]
    }
  ]
}